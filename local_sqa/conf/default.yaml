hydra:
  run:
    dir: ${base_dir}

defaults:
  - _self_
  - encoder: wav2vec2_base
  - decoder: transformer

launch:
  init: false  # If true, write config to experiment dir and return
  test_run: false  # If true, run a quick test of the training loop
  dry_run: false  # If true, write checkpoints to /tmp
  train: true
  accelerator: auto
  resume: false  # Resume training from last checkpoint in storage_dir

# Database to use for training and validation
databases:
  bvcc:
    factory: local_sqa.modules.data_loader.JsonParser
    json_path: ../data/bvcc.json
    train_dataset_names: train_main
    val_dataset_names: val_main
    mos_key: rating.mean
    min_length_in_seconds: 2.0
  nisqa:
    factory: local_sqa.modules.data_loader.JsonParser
    json_path: ../data/nisqa.json
    train_dataset_names: train_sim
    val_dataset_names: val_sim
    mos_key: rating.mean
    min_length_in_seconds: 2.0

max_total_size: 4800000  # 300s
train_dataloader:
  factory: local_sqa.modules.data_loader.Dataloader
  batch_size: 48
  max_total_size: ${max_total_size}
  max_padding_rate: 0.1
  target_sampling_rate: 16_000
  num_workers: -1
  resample: true
val_dataloader:
  factory: local_sqa.modules.data_loader.Dataloader
  batch_size: 48
  stage: val
  max_total_size: ${max_total_size}
  max_padding_rate: 0.1
  target_sampling_rate: 16_000
  num_workers: -1
  seed: 0
  resample: true

# Validation metric to monitor for learning rate scheduling and early stopping
validation:
  metric: SRCC
  maximize: true
  n_back_off: 0
  lr_update_factor: 3.33e-1
  back_off_patience: null

base_dir: ../../exp
lr: 1e-4
min_lr: 1e-6
num_seeds: 100
sub_iterator_length: 400
zero_init: false

trainer:
  storage_dir: null
  stop_trigger:  # Stop training after this number of iterations/epochs
  - 100
  - "epoch"
  summary_trigger:  # Write summaries to tensorboard after this number of iterations/epochs
  - 1_000
  - "iteration"
  checkpoint_trigger:  # Write a checkpoint after this number of iterations/epochs
  - 1
  - "epoch"
  optimizer:
    factory: padertorch.optimizer.Adam
    lr: ${lr}
    gradient_clipping: 10.
  model:
    factory: local_sqa.modules.ssl_mos.SSLMOS
    proj_in_size: ${proj_in_size}
    bias: 0.
    scale: 1.
    target_key: mos
    normalize_ratings: true
    out_activation: tanh
    standardize_audio: true
    equal_loudness: true
    l2_normalization: true
    criterion:
      factory: torch.nn.L1Loss
      reduction: none
    loss_weights:
      regression: 1.
      contrastive_loss: 1.
      consistency_loss_emb: 10.
      consistency_loss_scores: 0.
    slicer:
      factory: local_sqa.modules.slicer.Slicer
      sampling_rate: ${encoder_frame_rate}
      min_length_in_seconds: 0.2
      max_length_in_seconds: 1.0
      sequence_axis: -2
